{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "18jg9Sa2IiZ2BMKbRW3NEQwxqxb9n3DH0",
      "authorship_tag": "ABX9TyM5DZjHEHda+bqOosjK8ezt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vbonato/cnnTestBench/blob/main/pauNaJaca.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBoqo2tH2d6g"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "v9NgXTUH3Z0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "**Dataset WISDM**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IVtz1oB_0MmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create time windows\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "import re\n",
        "\n",
        "# Function to create time windows\n",
        "def create_time_windows(data, labels, window_size):\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(data) - window_size):\n",
        "        X.append(data[i:i + window_size])  # Select window of data\n",
        "        y.append(labels[i + (window_size-1)])  # Label is from the last element of the window\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Updated data loading function\n",
        "def load_data(file_path):\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            # Use regular expression to match the pattern {{feature_vector}, label}\n",
        "            match = re.match(r\"\\{\\{([0-9.,-]+)\\},\\s*(\\d+)\\}\", line.strip())\n",
        "\n",
        "            if match:\n",
        "                # Extract feature vector and label\n",
        "                feature_str = match.group(1)  # The feature string \"8.24,-2.11,3.87\"\n",
        "                label = int(match.group(2))  # The label \"4\"\n",
        "\n",
        "                # Convert the feature string to a list of floats\n",
        "                feature_vector = list(map(float, feature_str.split(',')))\n",
        "\n",
        "                features.append(feature_vector)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "# Load train and test data\n",
        "train_data_file = '/content/drive/MyDrive/MyBox/prof/projetos de pesquisa/pauNaJaca/dataset/WISDM/HAR-Dataset/train.dat'  # Adjust path to your file\n",
        "test_data_file = '/content/drive/MyDrive/MyBox/prof/projetos de pesquisa/pauNaJaca/dataset/WISDM/HAR-Dataset/test.dat'  # Adjust path to your file\n",
        "\n",
        "# Define the window size\n",
        "window_size = 200\n",
        "\n",
        "# Create time windows\n",
        "X_train, y_train = load_data(train_data_file)\n",
        "X_train, y_train = create_time_windows(X_train, y_train, window_size)\n",
        "\n",
        "X_test, y_test = load_data(test_data_file)\n",
        "X_test, y_test = create_time_windows(X_test, y_test, window_size)\n",
        "\n",
        "# Print the first feature vector and label\n",
        "print(\"First feature vector in X_train:\")\n",
        "print(X_train[0])  # First row (first feature vector)\n",
        "print(\"First label in y_train:\")\n",
        "print(y_train[0])  # First label\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)  # For classification (long type for labels)\n",
        "\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# Print the first feature vector and label\n",
        "print(\"First feature vector in X_train:\")\n",
        "print(X_train[0])  # First row (first feature vector)\n",
        "print(\"First label in y_train:\")\n",
        "print(y_train[0])  # First label\n",
        "\n",
        "# Check the shapes of the loaded data\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "yh6d-g0vBXZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a22bf25b-ca3e-44d6-8c89-57d384c83311"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First feature vector in X_train:\n",
            "[[ -0.6946377   12.680544     0.50395286]\n",
            " [  5.012288    11.264028     0.95342433]\n",
            " [  4.903325    10.882658    -0.08172209]\n",
            " [ -0.61291564  18.496431     3.0237172 ]\n",
            " [ -1.1849703   12.108489     7.205164  ]\n",
            " [  1.3756552   -2.4925237   -6.510526  ]\n",
            " [ -0.61291564  10.56939      5.706926  ]\n",
            " [ -0.50395286  13.947236     7.0553403 ]\n",
            " [ -8.430995    11.413852     5.134871  ]\n",
            " [  0.95342433   1.3756552    1.6480621 ]\n",
            " [ -8.19945     19.57244      2.7240696 ]\n",
            " [  1.4165162    5.7886477    2.982856  ]\n",
            " [ -1.879608    -2.982856    -0.29964766]\n",
            " [ -6.1291566    6.851035    -8.158588  ]\n",
            " [  5.829509    18.0061       8.539958  ]\n",
            " [  6.2789803    2.982856     2.9147544 ]\n",
            " [ -1.56634      8.308413    -1.4573772 ]\n",
            " [  3.5276701   13.593107     9.425281  ]\n",
            " [ -2.0294318   -5.706926   -10.18802   ]\n",
            " [  2.7649305   10.337844    -9.724928  ]\n",
            " [  3.568531    13.6748295    1.5390993 ]\n",
            " [ -0.50395286   3.8681788    3.718355  ]\n",
            " [ -2.3018389    1.6889231    0.08172209]\n",
            " [ -3.568531    19.57244      6.510526  ]\n",
            " [ -0.8036005   -3.2961242   -4.630918  ]\n",
            " [  0.50395286  10.841797    13.525005  ]\n",
            " [  5.706926    15.595298     6.1700177 ]\n",
            " [ -8.662541     7.273266     4.0180025 ]\n",
            " [ -1.334794     1.2258313    2.3699405 ]\n",
            " [ -4.5900574   19.57244      4.7126403 ]\n",
            " [  3.8681788    3.759216     0.84446156]\n",
            " [ -1.7978859    1.5390993    8.730643  ]\n",
            " [  7.668256    11.264028    -1.3075534 ]\n",
            " [ -2.3699405   14.2877445    8.281172  ]\n",
            " [  2.7240696    1.4573772    0.88532263]\n",
            " [ -3.5957718   18.659876    -0.6537767 ]\n",
            " [  3.9499009    4.140586     3.990762  ]\n",
            " [  0.46309182  -2.4108016    2.4108016 ]\n",
            " [  3.7864566   14.137921    -3.1463003 ]\n",
            " [  3.336985    19.231932     6.5513873 ]\n",
            " [  5.6660647    3.7864566    0.53119355]\n",
            " [  0.23154591   0.7627395    0.7627395 ]\n",
            " [ -4.8216033   19.57244      8.158588  ]\n",
            " [  1.8387469   -1.1168685   -2.7921712 ]\n",
            " [ -3.2961242   10.079058    13.824653  ]\n",
            " [ 11.604536    17.079916     1.334794  ]\n",
            " [ -3.173541    14.015338     5.706926  ]\n",
            " [  0.61291564   1.1168685    2.5606253 ]\n",
            " [ -7.8861814   19.57244      1.9885708 ]\n",
            " [  3.1463003    5.243834     4.671779  ]\n",
            " [ -3.0237172   -4.3312707   -3.336985  ]\n",
            " [ -0.08172209  11.917805    -7.8861814 ]\n",
            " [ -1.0351465   14.818938     4.6036777 ]\n",
            " [ -2.4516625    2.5333846    3.486809  ]\n",
            " [ -1.3756552    2.070293    -0.19068487]\n",
            " [ -2.4925237   19.57244      6.469665  ]\n",
            " [  1.4573772   -5.243834    -4.372132  ]\n",
            " [ -1.4165162    9.80665      5.7477865 ]\n",
            " [ -1.2666923   14.709975     6.2108784 ]\n",
            " [ -3.6774938    3.173541     3.7864566 ]\n",
            " [  1.8387469    2.7649305   -1.7570249 ]\n",
            " [ -1.2666923   19.313654     6.3198414 ]\n",
            " [  2.4108016   -7.6546354   -6.1291566 ]\n",
            " [ -0.61291564  16.358038     4.944186  ]\n",
            " [  0.04086104  17.502148     2.5333846 ]\n",
            " [ -7.6546354    7.8180795    4.372132  ]\n",
            " [ -1.2666923    0.7218784    0.8036005 ]\n",
            " [ -5.012288    19.57244      5.5162406 ]\n",
            " [  1.9477097    2.7921712    2.070293  ]\n",
            " [ -5.053149     1.6480621    7.6273947 ]\n",
            " [  9.384419    13.443283     1.0351465 ]\n",
            " [ -5.434519    13.211738     6.4424243 ]\n",
            " [ -0.61291564   1.879608     1.4165162 ]\n",
            " [  4.7126403   -6.5513873   -6.0201936 ]\n",
            " [ -1.7570249    9.302697    -6.428804  ]\n",
            " [ -0.9125633   10.501288    -0.27240697]\n",
            " [  2.6014864   19.381754     4.440233  ]\n",
            " [  5.7886477    3.214402     1.1441092 ]\n",
            " [ -1.9885708   12.4489975   -2.7240696 ]\n",
            " [  1.4165162   16.780268     8.471856  ]\n",
            " [  0.42223078  -8.267551    -7.3549876 ]\n",
            " [ -3.568531    10.95076     -0.8036005 ]\n",
            " [ -4.671779    11.727119     0.38136974]\n",
            " [ -2.1383946    1.6889231    3.5276701 ]\n",
            " [ -1.334794     2.4925237   -0.3405087 ]\n",
            " [ -2.9147544   19.57244      7.5865335 ]\n",
            " [  3.5276701   -3.9499009   -1.920469  ]\n",
            " [ -4.0588636   10.038197    14.2877445 ]\n",
            " [  7.5865335   13.33432      3.8681788 ]\n",
            " [ -5.175732    14.1787815    5.5162406 ]\n",
            " [  1.1849703    2.1111538    2.2201166 ]\n",
            " [ -3.718355    19.463476    -0.8036005 ]\n",
            " [  3.173541     6.510526     4.2086873 ]\n",
            " [ -1.7297841   -5.6252036   -4.3312707 ]\n",
            " [  0.84446156  12.980191    11.563675  ]\n",
            " [  2.7649305   17.352324     7.7363577 ]\n",
            " [  2.3426998   15.894946     3.6774938 ]\n",
            " [  4.7943625    3.8273177    0.9942854 ]\n",
            " [ -1.8387469   12.830367    -1.56634   ]\n",
            " [  5.366417    14.410328     6.742072  ]\n",
            " [  2.1111538    0.27240697   2.6423476 ]\n",
            " [  4.2086873   11.454713     7.6273947 ]\n",
            " [ -5.134871     9.00305     -3.173541  ]\n",
            " [  3.0237172    7.164303     0.08172209]\n",
            " [  2.070293     3.486809     1.7570249 ]\n",
            " [ -3.1054392    4.862464    -0.04086104]\n",
            " [ -4.399372    19.531578     5.053149  ]\n",
            " [  4.7535014   -3.2961242   -2.1383946 ]\n",
            " [ -0.6946377   -7.6273947   -7.8180795 ]\n",
            " [ -2.8330324    6.5513873   -7.9679036 ]\n",
            " [ -0.8036005   10.460427     0.23154591]\n",
            " [ -3.214402     3.0645783    3.255263  ]\n",
            " [ -2.8738933    3.5957718    0.10896278]\n",
            " [ -4.4810944   19.504337     5.9793324 ]\n",
            " [  2.7921712   -1.7570249    0.19068487]\n",
            " [ -4.7535014    4.2086873   11.141444  ]\n",
            " [ -1.56634      3.759216     3.255263  ]\n",
            " [ -3.214402     2.9556155    0.7627395 ]\n",
            " [ -2.6423476   19.57244      8.008764  ]\n",
            " [  0.5720546   -1.4982382   -0.38136974]\n",
            " [ -1.525479    -7.7363577   -8.580819  ]\n",
            " [ -4.7535014   18.537292    -3.1054392 ]\n",
            " [  1.7978859   14.410328     1.0760075 ]\n",
            " [ -0.8036005    3.255263     3.990762  ]\n",
            " [ -1.2258313    3.990762     0.8036005 ]\n",
            " [ -4.630918    19.57244      6.3607025 ]\n",
            " [  1.9885708   -1.3756552   -0.5720546 ]\n",
            " [ -4.630918     1.920469     8.281172  ]\n",
            " [ 12.299174    17.883516     5.325556  ]\n",
            " [  0.9942854   15.241169     5.325556  ]\n",
            " [  1.0351465    1.7570249    1.9885708 ]\n",
            " [ -9.384419    19.57244      0.10896278]\n",
            " [  2.9556155    5.597963     4.630918  ]\n",
            " [ -2.3699405   -5.366417    -2.7513103 ]\n",
            " [ -1.879608    10.882658    -7.7772183 ]\n",
            " [  1.1168685   18.496431     3.5957718 ]\n",
            " [  5.012288     4.372132     1.334794  ]\n",
            " [ -3.336985    16.589584    -4.671779  ]\n",
            " [ -6.891896    19.57244      6.238119  ]\n",
            " [  3.3778462   -0.6537767    2.3018389 ]\n",
            " [ -2.1383946   15.554437     4.372132  ]\n",
            " [  5.284695     1.6480621   -0.29964766]\n",
            " [ -9.425281    18.959524    -4.903325  ]\n",
            " [  2.070293    19.57244      8.008764  ]\n",
            " [  1.6480621   -2.6014864   -1.4573772 ]\n",
            " [ -1.56634     -7.7772183   -9.112013  ]\n",
            " [ -6.932757    13.33432     -6.3198414 ]\n",
            " [ -4.140586    12.871228    -0.84446156]\n",
            " [  3.0237172    2.3699405    2.0294318 ]\n",
            " [ -1.9885708    5.9793324    0.04086104]\n",
            " [  2.9556155   19.57244      7.6273947 ]\n",
            " [  1.7297841   -5.325556    -2.7513103 ]\n",
            " [ -0.42223078  14.1787815    9.888372  ]\n",
            " [  3.1463003   17.24336      5.407278  ]\n",
            " [ -0.5720546   18.727978     4.671779  ]\n",
            " [  5.5162406    3.7864566    1.1849703 ]\n",
            " [ -4.3312707   15.6634      -3.445948  ]\n",
            " [  5.5571017   14.709975     7.43671   ]\n",
            " [  0.50395286  -7.7772183   -8.921328  ]\n",
            " [ -4.7126403    6.891896   -11.032481  ]\n",
            " [ -1.7297841    8.962189    -2.1111538 ]\n",
            " [ -3.214402     3.486809     3.6774938 ]\n",
            " [ -2.3018389    0.84446156   1.3075534 ]\n",
            " [ -4.7943625   18.428331    -4.9850473 ]\n",
            " [  4.0588636   14.628253     9.00305   ]\n",
            " [  1.6889231   -0.7218784    1.3075534 ]\n",
            " [  2.2609777   15.213928     7.5865335 ]\n",
            " [  2.2609777   18.578154     4.630918  ]\n",
            " [  5.597963     4.630918    -0.08172209]\n",
            " [ -2.070293     1.8387469    1.0351465 ]\n",
            " [ -5.706926    19.57244      6.4015636 ]\n",
            " [  1.6889231   -1.9885708    0.42223078]\n",
            " [ -3.1463003    0.23154591   5.597963  ]\n",
            " [  5.7477865   15.28203      1.0351465 ]\n",
            " [  2.4516625   19.340895     5.366417  ]\n",
            " [  5.706926     4.2086873    1.56634   ]\n",
            " [ -3.5276701    8.049625    -0.61291564]\n",
            " [  5.284695    16.358038     9.112013  ]\n",
            " [  0.08172209  -6.701211    -7.5456724 ]\n",
            " [ -6.5513873   17.011814    -4.372132  ]\n",
            " [ -0.23154591  15.5135765    0.8036005 ]\n",
            " [ -4.5628166    4.0180025    3.0645783 ]\n",
            " [ -0.50395286   0.6946377   -0.27240697]\n",
            " [ -0.50395286  19.57244      7.6954966 ]\n",
            " [  0.313268    -2.1792557   -2.1111538 ]\n",
            " [ -1.9477097    6.701211    11.686258  ]\n",
            " [  7.1234417   16.276316     2.8330324 ]\n",
            " [  2.152015    18.727978     4.8216033 ]\n",
            " [ -9.00305      5.407278     2.7921712 ]\n",
            " [  5.706926     4.7126403    0.6537767 ]\n",
            " [ -7.014479    17.270601    -6.3198414 ]\n",
            " [  7.9270425   12.830367     7.6273947 ]\n",
            " [ -0.          -6.742072    -8.349273  ]\n",
            " [ -3.2961242    2.5606253    9.575105  ]\n",
            " [  6.5513873   16.86199      2.2201166 ]\n",
            " [ -0.95342433  17.052675     4.4810944 ]\n",
            " [  3.2961242    4.2904096    0.08172209]\n",
            " [ -6.510526    18.115063    -5.8567495 ]\n",
            " [  5.9793324   10.501288     7.1234417 ]\n",
            " [ -0.5720546   -6.1291566   -9.112013  ]]\n",
            "First label in y_train:\n",
            "0\n",
            "First feature vector in X_train:\n",
            "tensor([[ -0.6946,  12.6805,   0.5040],\n",
            "        [  5.0123,  11.2640,   0.9534],\n",
            "        [  4.9033,  10.8827,  -0.0817],\n",
            "        [ -0.6129,  18.4964,   3.0237],\n",
            "        [ -1.1850,  12.1085,   7.2052],\n",
            "        [  1.3757,  -2.4925,  -6.5105],\n",
            "        [ -0.6129,  10.5694,   5.7069],\n",
            "        [ -0.5040,  13.9472,   7.0553],\n",
            "        [ -8.4310,  11.4139,   5.1349],\n",
            "        [  0.9534,   1.3757,   1.6481],\n",
            "        [ -8.1994,  19.5724,   2.7241],\n",
            "        [  1.4165,   5.7886,   2.9829],\n",
            "        [ -1.8796,  -2.9829,  -0.2996],\n",
            "        [ -6.1292,   6.8510,  -8.1586],\n",
            "        [  5.8295,  18.0061,   8.5400],\n",
            "        [  6.2790,   2.9829,   2.9148],\n",
            "        [ -1.5663,   8.3084,  -1.4574],\n",
            "        [  3.5277,  13.5931,   9.4253],\n",
            "        [ -2.0294,  -5.7069, -10.1880],\n",
            "        [  2.7649,  10.3378,  -9.7249],\n",
            "        [  3.5685,  13.6748,   1.5391],\n",
            "        [ -0.5040,   3.8682,   3.7184],\n",
            "        [ -2.3018,   1.6889,   0.0817],\n",
            "        [ -3.5685,  19.5724,   6.5105],\n",
            "        [ -0.8036,  -3.2961,  -4.6309],\n",
            "        [  0.5040,  10.8418,  13.5250],\n",
            "        [  5.7069,  15.5953,   6.1700],\n",
            "        [ -8.6625,   7.2733,   4.0180],\n",
            "        [ -1.3348,   1.2258,   2.3699],\n",
            "        [ -4.5901,  19.5724,   4.7126],\n",
            "        [  3.8682,   3.7592,   0.8445],\n",
            "        [ -1.7979,   1.5391,   8.7306],\n",
            "        [  7.6683,  11.2640,  -1.3076],\n",
            "        [ -2.3699,  14.2877,   8.2812],\n",
            "        [  2.7241,   1.4574,   0.8853],\n",
            "        [ -3.5958,  18.6599,  -0.6538],\n",
            "        [  3.9499,   4.1406,   3.9908],\n",
            "        [  0.4631,  -2.4108,   2.4108],\n",
            "        [  3.7865,  14.1379,  -3.1463],\n",
            "        [  3.3370,  19.2319,   6.5514],\n",
            "        [  5.6661,   3.7865,   0.5312],\n",
            "        [  0.2315,   0.7627,   0.7627],\n",
            "        [ -4.8216,  19.5724,   8.1586],\n",
            "        [  1.8387,  -1.1169,  -2.7922],\n",
            "        [ -3.2961,  10.0791,  13.8247],\n",
            "        [ 11.6045,  17.0799,   1.3348],\n",
            "        [ -3.1735,  14.0153,   5.7069],\n",
            "        [  0.6129,   1.1169,   2.5606],\n",
            "        [ -7.8862,  19.5724,   1.9886],\n",
            "        [  3.1463,   5.2438,   4.6718],\n",
            "        [ -3.0237,  -4.3313,  -3.3370],\n",
            "        [ -0.0817,  11.9178,  -7.8862],\n",
            "        [ -1.0351,  14.8189,   4.6037],\n",
            "        [ -2.4517,   2.5334,   3.4868],\n",
            "        [ -1.3757,   2.0703,  -0.1907],\n",
            "        [ -2.4925,  19.5724,   6.4697],\n",
            "        [  1.4574,  -5.2438,  -4.3721],\n",
            "        [ -1.4165,   9.8067,   5.7478],\n",
            "        [ -1.2667,  14.7100,   6.2109],\n",
            "        [ -3.6775,   3.1735,   3.7865],\n",
            "        [  1.8387,   2.7649,  -1.7570],\n",
            "        [ -1.2667,  19.3137,   6.3198],\n",
            "        [  2.4108,  -7.6546,  -6.1292],\n",
            "        [ -0.6129,  16.3580,   4.9442],\n",
            "        [  0.0409,  17.5021,   2.5334],\n",
            "        [ -7.6546,   7.8181,   4.3721],\n",
            "        [ -1.2667,   0.7219,   0.8036],\n",
            "        [ -5.0123,  19.5724,   5.5162],\n",
            "        [  1.9477,   2.7922,   2.0703],\n",
            "        [ -5.0531,   1.6481,   7.6274],\n",
            "        [  9.3844,  13.4433,   1.0351],\n",
            "        [ -5.4345,  13.2117,   6.4424],\n",
            "        [ -0.6129,   1.8796,   1.4165],\n",
            "        [  4.7126,  -6.5514,  -6.0202],\n",
            "        [ -1.7570,   9.3027,  -6.4288],\n",
            "        [ -0.9126,  10.5013,  -0.2724],\n",
            "        [  2.6015,  19.3818,   4.4402],\n",
            "        [  5.7886,   3.2144,   1.1441],\n",
            "        [ -1.9886,  12.4490,  -2.7241],\n",
            "        [  1.4165,  16.7803,   8.4719],\n",
            "        [  0.4222,  -8.2676,  -7.3550],\n",
            "        [ -3.5685,  10.9508,  -0.8036],\n",
            "        [ -4.6718,  11.7271,   0.3814],\n",
            "        [ -2.1384,   1.6889,   3.5277],\n",
            "        [ -1.3348,   2.4925,  -0.3405],\n",
            "        [ -2.9148,  19.5724,   7.5865],\n",
            "        [  3.5277,  -3.9499,  -1.9205],\n",
            "        [ -4.0589,  10.0382,  14.2877],\n",
            "        [  7.5865,  13.3343,   3.8682],\n",
            "        [ -5.1757,  14.1788,   5.5162],\n",
            "        [  1.1850,   2.1112,   2.2201],\n",
            "        [ -3.7184,  19.4635,  -0.8036],\n",
            "        [  3.1735,   6.5105,   4.2087],\n",
            "        [ -1.7298,  -5.6252,  -4.3313],\n",
            "        [  0.8445,  12.9802,  11.5637],\n",
            "        [  2.7649,  17.3523,   7.7364],\n",
            "        [  2.3427,  15.8949,   3.6775],\n",
            "        [  4.7944,   3.8273,   0.9943],\n",
            "        [ -1.8387,  12.8304,  -1.5663],\n",
            "        [  5.3664,  14.4103,   6.7421],\n",
            "        [  2.1112,   0.2724,   2.6423],\n",
            "        [  4.2087,  11.4547,   7.6274],\n",
            "        [ -5.1349,   9.0030,  -3.1735],\n",
            "        [  3.0237,   7.1643,   0.0817],\n",
            "        [  2.0703,   3.4868,   1.7570],\n",
            "        [ -3.1054,   4.8625,  -0.0409],\n",
            "        [ -4.3994,  19.5316,   5.0531],\n",
            "        [  4.7535,  -3.2961,  -2.1384],\n",
            "        [ -0.6946,  -7.6274,  -7.8181],\n",
            "        [ -2.8330,   6.5514,  -7.9679],\n",
            "        [ -0.8036,  10.4604,   0.2315],\n",
            "        [ -3.2144,   3.0646,   3.2553],\n",
            "        [ -2.8739,   3.5958,   0.1090],\n",
            "        [ -4.4811,  19.5043,   5.9793],\n",
            "        [  2.7922,  -1.7570,   0.1907],\n",
            "        [ -4.7535,   4.2087,  11.1414],\n",
            "        [ -1.5663,   3.7592,   3.2553],\n",
            "        [ -3.2144,   2.9556,   0.7627],\n",
            "        [ -2.6423,  19.5724,   8.0088],\n",
            "        [  0.5721,  -1.4982,  -0.3814],\n",
            "        [ -1.5255,  -7.7364,  -8.5808],\n",
            "        [ -4.7535,  18.5373,  -3.1054],\n",
            "        [  1.7979,  14.4103,   1.0760],\n",
            "        [ -0.8036,   3.2553,   3.9908],\n",
            "        [ -1.2258,   3.9908,   0.8036],\n",
            "        [ -4.6309,  19.5724,   6.3607],\n",
            "        [  1.9886,  -1.3757,  -0.5721],\n",
            "        [ -4.6309,   1.9205,   8.2812],\n",
            "        [ 12.2992,  17.8835,   5.3256],\n",
            "        [  0.9943,  15.2412,   5.3256],\n",
            "        [  1.0351,   1.7570,   1.9886],\n",
            "        [ -9.3844,  19.5724,   0.1090],\n",
            "        [  2.9556,   5.5980,   4.6309],\n",
            "        [ -2.3699,  -5.3664,  -2.7513],\n",
            "        [ -1.8796,  10.8827,  -7.7772],\n",
            "        [  1.1169,  18.4964,   3.5958],\n",
            "        [  5.0123,   4.3721,   1.3348],\n",
            "        [ -3.3370,  16.5896,  -4.6718],\n",
            "        [ -6.8919,  19.5724,   6.2381],\n",
            "        [  3.3778,  -0.6538,   2.3018],\n",
            "        [ -2.1384,  15.5544,   4.3721],\n",
            "        [  5.2847,   1.6481,  -0.2996],\n",
            "        [ -9.4253,  18.9595,  -4.9033],\n",
            "        [  2.0703,  19.5724,   8.0088],\n",
            "        [  1.6481,  -2.6015,  -1.4574],\n",
            "        [ -1.5663,  -7.7772,  -9.1120],\n",
            "        [ -6.9328,  13.3343,  -6.3198],\n",
            "        [ -4.1406,  12.8712,  -0.8445],\n",
            "        [  3.0237,   2.3699,   2.0294],\n",
            "        [ -1.9886,   5.9793,   0.0409],\n",
            "        [  2.9556,  19.5724,   7.6274],\n",
            "        [  1.7298,  -5.3256,  -2.7513],\n",
            "        [ -0.4222,  14.1788,   9.8884],\n",
            "        [  3.1463,  17.2434,   5.4073],\n",
            "        [ -0.5721,  18.7280,   4.6718],\n",
            "        [  5.5162,   3.7865,   1.1850],\n",
            "        [ -4.3313,  15.6634,  -3.4459],\n",
            "        [  5.5571,  14.7100,   7.4367],\n",
            "        [  0.5040,  -7.7772,  -8.9213],\n",
            "        [ -4.7126,   6.8919, -11.0325],\n",
            "        [ -1.7298,   8.9622,  -2.1112],\n",
            "        [ -3.2144,   3.4868,   3.6775],\n",
            "        [ -2.3018,   0.8445,   1.3076],\n",
            "        [ -4.7944,  18.4283,  -4.9850],\n",
            "        [  4.0589,  14.6283,   9.0030],\n",
            "        [  1.6889,  -0.7219,   1.3076],\n",
            "        [  2.2610,  15.2139,   7.5865],\n",
            "        [  2.2610,  18.5782,   4.6309],\n",
            "        [  5.5980,   4.6309,  -0.0817],\n",
            "        [ -2.0703,   1.8387,   1.0351],\n",
            "        [ -5.7069,  19.5724,   6.4016],\n",
            "        [  1.6889,  -1.9886,   0.4222],\n",
            "        [ -3.1463,   0.2315,   5.5980],\n",
            "        [  5.7478,  15.2820,   1.0351],\n",
            "        [  2.4517,  19.3409,   5.3664],\n",
            "        [  5.7069,   4.2087,   1.5663],\n",
            "        [ -3.5277,   8.0496,  -0.6129],\n",
            "        [  5.2847,  16.3580,   9.1120],\n",
            "        [  0.0817,  -6.7012,  -7.5457],\n",
            "        [ -6.5514,  17.0118,  -4.3721],\n",
            "        [ -0.2315,  15.5136,   0.8036],\n",
            "        [ -4.5628,   4.0180,   3.0646],\n",
            "        [ -0.5040,   0.6946,  -0.2724],\n",
            "        [ -0.5040,  19.5724,   7.6955],\n",
            "        [  0.3133,  -2.1793,  -2.1112],\n",
            "        [ -1.9477,   6.7012,  11.6863],\n",
            "        [  7.1234,  16.2763,   2.8330],\n",
            "        [  2.1520,  18.7280,   4.8216],\n",
            "        [ -9.0030,   5.4073,   2.7922],\n",
            "        [  5.7069,   4.7126,   0.6538],\n",
            "        [ -7.0145,  17.2706,  -6.3198],\n",
            "        [  7.9270,  12.8304,   7.6274],\n",
            "        [ -0.0000,  -6.7421,  -8.3493],\n",
            "        [ -3.2961,   2.5606,   9.5751],\n",
            "        [  6.5514,  16.8620,   2.2201],\n",
            "        [ -0.9534,  17.0527,   4.4811],\n",
            "        [  3.2961,   4.2904,   0.0817],\n",
            "        [ -6.5105,  18.1151,  -5.8567],\n",
            "        [  5.9793,  10.5013,   7.1234],\n",
            "        [ -0.5721,  -6.1292,  -9.1120]])\n",
            "First label in y_train:\n",
            "tensor(0)\n",
            "X_train shape: torch.Size([738242, 200, 3]), y_train shape: torch.Size([738242])\n",
            "X_test shape: torch.Size([316272, 200, 3]), y_test shape: torch.Size([316272])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        # CNN layers\n",
        "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=16, kernel_size=3, padding=1)  # input channels = number of features\n",
        "        #self.conv2 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding=1)  # input channels = number of features\n",
        "\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        # Calculate the input size for the fully connected layer based on the output size of conv1\n",
        "        self.fc1 = nn.Linear(16 * (X_train.shape[1] // 2), 64)  # Flattened size after pooling\n",
        "        self.fc2 = nn.Linear(64, 6)  # Assuming 6 classes for classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)  # Add channel dimension (change shape to [batch_size, channels, seq_length])\n",
        "\n",
        "        #x = torch.relu(self.conv1(x))  # Apply conv1 and pooling\n",
        "        #x = self.pool(torch.relu(self.conv2(x)))  # Apply conv2 and pooling\n",
        "        x = self.pool(torch.relu(self.conv1(x)))  # Apply conv1 and pooling\n",
        "\n",
        "        x = x.view(-1, 16 * (x.shape[2]))  # Flatten for fully connected layer\n",
        "        x = torch.relu(self.fc1(x))  # Apply first fully connected layer\n",
        "        x = self.fc2(x)  # Output layer (no activation since we'll apply softmax in loss)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Initialize the model\n",
        "model = SimpleCNN()\n",
        "\n",
        "# Loss function (cross-entropy for classification)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer (Adam)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# DataLoader for batching\n",
        "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "g2wLGd2VBRmq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 1  # You can adjust the number of epochs\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "    correct_preds = 0\n",
        "    total_preds = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        outputs = model(inputs)  # Forward pass\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        # Track loss and accuracy\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_preds += (predicted == labels).sum().item()\n",
        "        total_preds += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = correct_preds / total_preds\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")"
      ],
      "metadata": {
        "id": "tGh-L7AvBg3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d31599a0-ee87-46c0-f070-bdb6c51db4c8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, Loss: 0.1862, Accuracy: 0.9363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model.eval()  # Set model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_test)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    correct_preds = (predicted == y_test).sum().item()\n",
        "    accuracy = correct_preds / len(y_test)\n",
        "    print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIhh3n6iBlDB",
        "outputId": "5f11724c-2bea-48e0-938c-8dd09d59f38e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8060\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'simple_cnn_model.pth')\n",
        "\n",
        "# Load the model (if needed)\n",
        "model = SimpleCNN()\n",
        "model.load_state_dict(torch.load('simple_cnn_model.pth'))\n",
        "model.eval()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "b3hDlz-mBoIC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c37a634-5b5f-44f1-cc01-3225e986a1b5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleCNN(\n",
              "  (conv1): Conv1d(3, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=1600, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Post-Training Quantization ---\n",
        "\n",
        "# 1. Make sure the model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# 2. Prepare the model for quantization\n",
        "# Specify the \"backend\" for quantization. 'fbgemm' is for x86 CPUs.\n",
        "model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
        "quantized_model_ptq = torch.quantization.prepare(model, inplace=False) # Use False to keep original model\n",
        "\n",
        "# 3. Calibrate the model\n",
        "# We feed the model a few batches of data to observe activation ranges\n",
        "print(\"Calibrating the model...\")\n",
        "with torch.no_grad():\n",
        "    for inputs, _ in train_loader: # Use a few batches from your training data\n",
        "        quantized_model_ptq(inputs)\n",
        "\n",
        "print(\"Calibration done.\")\n",
        "\n",
        "# 4. Convert the model to a quantized version\n",
        "quantized_model_ptq = torch.quantization.convert(quantized_model_ptq, inplace=True)\n",
        "print(\"Model converted to quantized version.\")\n",
        "\n",
        "# Now you can use 'quantized_model_ptq' for inference\n",
        "# It will be faster and smaller!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEeaGy2g3R6f",
        "outputId": "17de7114-d739-4b46-8487-9d61dc8b1b16"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calibrating the model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2572704719.py:9: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
            "For migrations of users: \n",
            "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
            "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
            "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
            "see https://github.com/pytorch/ao/issues/2259 for more details\n",
            "  quantized_model_ptq = torch.quantization.prepare(model, inplace=False) # Use False to keep original model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calibration done.\n",
            "Model converted to quantized version.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2572704719.py:21: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
            "For migrations of users: \n",
            "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
            "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
            "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
            "see https://github.com/pytorch/ao/issues/2259 for more details\n",
            "  quantized_model_ptq = torch.quantization.convert(quantized_model_ptq, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install onnx onnxruntime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngIMSLXb5wal",
        "outputId": "33b99c27-7209-46f6-ac47-61563f6a4de7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.12/dist-packages (1.19.1)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.12/dist-packages (1.23.1)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.3)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.9.23)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (1.13.3)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Exports the model structure and weights into a single .onnx file ---\n",
        "\n",
        "import torch\n",
        "\n",
        "# Load the saved weights from your training session\n",
        "model.load_state_dict(torch.load('simple_cnn_model.pth'))\n",
        "model.eval() # Set the model to evaluation mode\n",
        "\n",
        "# --- Export to ONNX ---\n",
        "# Create a dummy input tensor with the correct shape: [batch_size, seq_length, features]\n",
        "# This shape must match your model's input exactly.\n",
        "dummy_input = torch.randn(1, window_size, 3)\n",
        "\n",
        "# Define the output file name\n",
        "onnx_file_path = \"simple_cnn_wisdm.onnx\"\n",
        "\n",
        "print(f\"Exporting model to {onnx_file_path}...\")\n",
        "\n",
        "# Export the model\n",
        "torch.onnx.export(model,               # The model to export\n",
        "                  dummy_input,         # A sample input\n",
        "                  onnx_file_path,      # Where to save the model\n",
        "                  export_params=True,  # Store the trained weights\n",
        "                  opset_version=12,    # The ONNX version to use\n",
        "                  input_names=['input'], # The name for the input tensor\n",
        "                  output_names=['output']) # The name for the output tensor\n",
        "\n",
        "print(\"Model has been successfully converted to ONNX format! ✅\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osArRyfW69zk",
        "outputId": "e02970c7-e0df-416c-aa56-3a02b90f54c9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exporting model to simple_cnn_wisdm.onnx...\n",
            "Model has been successfully converted to ONNX format! ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2239025766.py:20: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
            "  torch.onnx.export(model,               # The model to export\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "**Dataset PAMAP2**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "aB498o73z9yl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#remove columns heartrate and temp of the three IMUs\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Define the file path\n",
        "train_data_file = '/content/drive/MyDrive/MyBox/prof/projetos de pesquisa/pauNaJaca/dataset/PAMAP2/pamap2.csv'\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "df = pd.read_csv(train_data_file)\n",
        "\n",
        "# Remove columns\n",
        "df = df.drop(df.columns[2], axis=1)\n",
        "df = df.drop(df.columns[2], axis=1)\n",
        "df = df.drop(df.columns[11], axis=1)\n",
        "df = df.drop(df.columns[20], axis=1)\n",
        "\n",
        "\n",
        "# Save the updated DataFrame to a new CSV file\n",
        "output_file = '/content/drive/MyDrive/MyBox/prof/projetos de pesquisa/pauNaJaca/dataset/PAMAP2/pamap2_columns_removed.csv'\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "# Print a message to confirm that the file was saved\n",
        "print(f\"Updated CSV saved to: {output_file}\")\n"
      ],
      "metadata": {
        "id": "ybJnxdyB7hhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace the activity names in the first column with their corresponding IDs\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Define the file path for the modified CSV\n",
        "modified_train_data_file = '/content/drive/MyDrive/MyBox/prof/projetos de pesquisa/pauNaJaca/dataset/PAMAP2/pamap2_columns_removed.csv'\n",
        "\n",
        "# Load the modified CSV into a DataFrame without assuming a header\n",
        "df = pd.read_csv(modified_train_data_file, header=None)\n",
        "\n",
        "# Print the first few rows to check the content\n",
        "print(\"Original DataFrame first few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# Create a dictionary to map activity names to activity IDs\n",
        "activity_map = {\n",
        "    'lying': 1,\n",
        "    'sitting': 2,\n",
        "    'standing': 3,\n",
        "    'walking': 4,\n",
        "    'running': 5,\n",
        "    'cycling': 6,\n",
        "    'nordic_walking': 7,\n",
        "    'watching_TV': 9,\n",
        "    'computer_work': 10,\n",
        "    'car_driving': 11,\n",
        "    'ascending_stairs': 12,\n",
        "    'descending_stairs': 13,\n",
        "    'vacuum_cleaning': 16,\n",
        "    'ironing': 17,\n",
        "    'folding_laundry': 18,\n",
        "    'house_cleaning': 19,\n",
        "    'playing_soccer': 20,\n",
        "    'rope_jumping': 24,\n",
        "    'other': 0\n",
        "}\n",
        "\n",
        "# Replace the activity names in the first column with their corresponding IDs\n",
        "df.iloc[:, 0] = df.iloc[:, 0].map(activity_map)\n",
        "\n",
        "# Print the first few rows after the transformation to ensure it's working\n",
        "print(\"\\nDataFrame after replacing activity names with IDs:\")\n",
        "print(df.head())\n",
        "\n",
        "# Save the updated DataFrame to a new CSV file\n",
        "output_file = '/content/drive/MyDrive/MyBox/prof/projetos de pesquisa/pauNaJaca/dataset/PAMAP2/pamap2_with_activityIDs.csv'\n",
        "df.to_csv(output_file, index=False, header=False)\n",
        "\n",
        "# Print a confirmation message\n",
        "print(f\"Updated CSV with activity IDs saved to: {output_file}\")\n"
      ],
      "metadata": {
        "id": "zuGjD4IYE8mR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split CSV in train (excluding user 5) and test (only user 5) csv files\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Define the file path for the CSV file containing activity IDs\n",
        "train_data_file_with_ids = '/content/drive/MyDrive/MyBox/prof/projetos de pesquisa/pauNaJaca/dataset/PAMAP2/pamap2_with_activityIDs.csv'\n",
        "\n",
        "# Load the CSV file into a DataFrame without assuming a header\n",
        "df = pd.read_csv(train_data_file_with_ids, header=None)\n",
        "\n",
        "# Print the first few rows to check the content\n",
        "print(\"Original DataFrame first few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# Filter rows where the user ID is 5 and save them as test_pamap2.csv\n",
        "test_df = df[df.iloc[:, 1] == 5]\n",
        "test_df.to_csv('/content/drive/MyDrive/MyBox/prof/projetos de pesquisa/pauNaJaca/dataset/PAMAP2/test_pamap2.csv', index=False, header=False)\n",
        "\n",
        "# Filter rows where the user ID is not 5 (excluding) and save them as train_pamap2.csv\n",
        "train_df = df[df.iloc[:, 1] != 5]\n",
        "train_df.to_csv('/content/drive/MyDrive/MyBox/prof/projetos de pesquisa/pauNaJaca/dataset/PAMAP2/train_pamap2.csv', index=False, header=False)\n",
        "\n",
        "# Print a confirmation message\n",
        "print(\"Data has been split into train_pamap2.csv (excluding user ID 5) and test_pamap2.csv (user ID 5 only).\")\n"
      ],
      "metadata": {
        "id": "ColCz8mlHdJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert .csv to .dat\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Define file paths\n",
        "train_file = '/content/drive/MyDrive/MyBox/prof/projetos de pesquisa/pauNaJaca/dataset/PAMAP2/train_pamap2.csv'\n",
        "test_file = '/content/drive/MyDrive/MyBox/prof/projetos de pesquisa/pauNaJaca/dataset/PAMAP2/test_pamap2.csv'\n",
        "\n",
        "# Function to convert rows into the required format and save as .dat\n",
        "def convert_to_dat(input_file, output_file):\n",
        "    # Load the CSV file without a header\n",
        "    df = pd.read_csv(input_file, header=None)\n",
        "\n",
        "    # Open the output .dat file to write\n",
        "    with open(output_file, 'w') as file:\n",
        "        for _, row in df.iterrows():\n",
        "            # Convert row into the required format: {{column 2, column 3, column 4, ...}, column 0}\n",
        "            row_data = \"{{\" + \",\".join(map(str, row[2:])) + \"},\" + str(int(row[0])) + \"}\\n\"\n",
        "            file.write(row_data)\n",
        "\n",
        "# Convert train_pamap2.csv to train_pamap2.dat\n",
        "convert_to_dat(train_file, '/content/drive/MyDrive/MyBox/prof/projetos de pesquisa/pauNaJaca/dataset/PAMAP2/train_pamap2.dat')\n",
        "\n",
        "# Convert test_pamap2.csv to test_pamap2.dat\n",
        "convert_to_dat(test_file, '/content/drive/MyDrive/MyBox/prof/projetos de pesquisa/pauNaJaca/dataset/PAMAP2/test_pamap2.dat')\n",
        "\n",
        "print(\"Conversion to .dat files is complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cncd9etsQcGQ",
        "outputId": "30a72bcb-8efa-4113-b9c8-d0768d1e4d50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversion to .dat files is complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create time windows\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "import re\n",
        "\n",
        "# Function to create time windows\n",
        "def create_time_windows(data, labels, window_size):\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(data) - window_size):\n",
        "        X.append(data[i:i + window_size])  # Select window of data\n",
        "        y.append(labels[i + (window_size-1)])  # Label is from the last element of the window\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Updated data loading function\n",
        "def load_data(file_path):\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            # Use regular expression to match the pattern {{feature_vector}, label}\n",
        "            match = re.match(r\"\\{\\{([0-9.,-]+)\\},\\s*(\\d+)\\}\", line.strip())\n",
        "\n",
        "            if match:\n",
        "                # Extract feature vector and label\n",
        "                feature_str = match.group(1)  # The feature string \"8.24,-2.11,3.87\"\n",
        "                label = int(match.group(2))  # The label \"4\"\n",
        "\n",
        "                # Convert the feature string to a list of floats\n",
        "                feature_vector = list(map(float, feature_str.split(',')))\n",
        "\n",
        "                features.append(feature_vector)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "# Load train and test data\n",
        "train_data_file = '/content/drive/MyDrive/MyBox/prof/projetos de pesquisa/pauNaJaca/dataset/PAMAP2/train_pamap2.dat'  # Adjust path to your file\n",
        "test_data_file = '/content/drive/MyDrive/MyBox/prof/projetos de pesquisa/pauNaJaca/dataset/PAMAP2/test_pamap2.dat'  # Adjust path to your file\n",
        "\n",
        "print(\"File loaded:\")\n",
        "\n",
        "# Define the window size\n",
        "window_size = 10\n",
        "\n",
        "# Create time windows\n",
        "X_train, y_train = load_data(train_data_file)\n",
        "X_train, y_train = create_time_windows(X_train, y_train, window_size)\n",
        "\n",
        "X_test, y_test = load_data(test_data_file)\n",
        "X_test, y_test = create_time_windows(X_test, y_test, window_size)\n",
        "\n",
        "print(\"Time window created:\")\n",
        "\n",
        "# Print the first feature vector and label\n",
        "print(\"First feature vector in X_train:\")\n",
        "print(X_train[0])  # First row (first feature vector)\n",
        "print(\"Second feature vector in X_train:\")\n",
        "print(X_train[1])  # First row (first feature vector)\n",
        "\n",
        "print(\"First label in y_train:\")\n",
        "print(y_train[0])  # First label\n",
        "print(\"Second label in y_train:\")\n",
        "print(y_train[1])  # First label\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)  # For classification (long type for labels)\n",
        "\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# # Print the first feature vector and label\n",
        "# print(\"First feature vector in X_train:\")\n",
        "# print(X_train[0])  # First row (first feature vector)\n",
        "# print(\"First label in y_train:\")\n",
        "# print(y_train[0])  # First label\n",
        "\n",
        "# Check the shapes of the loaded data\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "id": "2cslxq8BXNTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a model\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        # CNN layers\n",
        "        self.conv1 = nn.Conv1d(in_channels=27, out_channels=27, kernel_size=3, padding=1)  # input channels = number of features\n",
        "        self.conv2 = nn.Conv1d(in_channels=27, out_channels=16, kernel_size=3, padding=1)  # input channels = number of features\n",
        "\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        # Calculate the input size for the fully connected layer based on the output size of conv1\n",
        "        self.fc1 = nn.Linear(16 * (X_train.shape[1] // 2), 64)  # Flattened size after pooling\n",
        "        self.fc2 = nn.Linear(64, 25)  # Assuming 25 classes for classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)  # Add channel dimension (change shape to [batch_size, channels, seq_length])\n",
        "\n",
        "        x = torch.relu(self.conv1(x))  # Apply conv1 and pooling\n",
        "        x = self.pool(torch.relu(self.conv2(x)))  # Apply conv2 and pooling\n",
        "        #x = self.pool(torch.relu(self.conv1(x)))  # Apply conv1 and pooling\n",
        "\n",
        "        x = x.view(-1, 16 * (x.shape[2]))  # Flatten for fully connected layer\n",
        "        x = torch.relu(self.fc1(x))  # Apply first fully connected layer\n",
        "        x = self.fc2(x)  # Output layer (no activation since we'll apply softmax in loss)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Initialize the model\n",
        "model = SimpleCNN()\n",
        "\n",
        "# Loss function (cross-entropy for classification)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer (Adam)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# DataLoader for batching\n",
        "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "O_gyZYu9XqYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "\n",
        "num_epochs = 3  # You can adjust the number of epochs\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "    correct_preds = 0\n",
        "    total_preds = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        outputs = model(inputs)  # Forward pass\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        # Track loss and accuracy\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_preds += (predicted == labels).sum().item()\n",
        "        total_preds += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = correct_preds / total_preds\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ufOIrAbaW1F",
        "outputId": "e93de07b-9973-41eb-b535-331cf2e3b713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.2979, Accuracy: 0.9041\n",
            "Epoch 2/3, Loss: 0.1936, Accuracy: 0.9378\n",
            "Epoch 3/3, Loss: 0.1731, Accuracy: 0.9447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model.eval()  # Set model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_test)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    correct_preds = (predicted == y_test).sum().item()\n",
        "    accuracy = correct_preds / len(y_test)\n",
        "    print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44agAuPBeDNd",
        "outputId": "fb075590-cbbb-45ef-a68d-d152490c3aae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.7133\n"
          ]
        }
      ]
    }
  ]
}